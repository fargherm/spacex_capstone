{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Space X  Falcon 9 First Stage Landing Prediction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping Falcon 9 and Falcon Heavy Launches Records from Wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be collecting SpaceX data by web scraping Falcon 9 historical launch records from a Wikipedia page titled `List of Falcon 9 and Falcon Heavy launches`\n",
    "\n",
    "[https://en.wikipedia.org/wiki/List_of_Falcon\\_9\\_and_Falcon_Heavy_launches](https://en.wikipedia.org/wiki/List_of_Falcon\\_9\\_and_Falcon_Heavy_launches?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "We will be web scraping using `BeautifulSoup` to gather Falcon 9 launch records:\n",
    "\n",
    "*   Extracting a Falcon 9 launch records HTML table from Wikipedia\n",
    "*   Parsing the table and converting it into a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by installing and importing the required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\fargh\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\fargh\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\fargh\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fargh\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fargh\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\fargh\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fargh\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some functions to help process a web scraped HTML table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the data and time from the HTML  table cell\n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]\n",
    "\n",
    "def booster_version(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the booster version from the HTML  table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=''.join([booster_version for i,booster_version in enumerate( table_cells.strings) if i%2==0][0:-1])\n",
    "    return out\n",
    "\n",
    "def landing_status(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=[i for i in table_cells.strings][0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_mass(table_cells):\n",
    "    mass=unicodedata.normalize(\"NFKD\", table_cells.text).strip()\n",
    "    if mass:\n",
    "        mass.find(\"kg\")\n",
    "        new_mass=mass[0:mass.find(\"kg\")+2]\n",
    "    else:\n",
    "        new_mass=0\n",
    "    return new_mass\n",
    "\n",
    "\n",
    "def extract_column_from_header(row):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    if (row.br):\n",
    "        row.br.extract()\n",
    "    if row.a:\n",
    "        row.a.extract()\n",
    "    if row.sup:\n",
    "        row.sup.extract()\n",
    "        \n",
    "    colunm_name = ' '.join(row.contents)\n",
    "    \n",
    "    # Filter the digit and empty names\n",
    "    if not(colunm_name.strip().isdigit()):\n",
    "        colunm_name = colunm_name.strip()\n",
    "        return colunm_name    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consistency, we will scrape the data from a snapshot of the  `List of Falcon 9 and Falcon Heavy launches` Wikipage updated on\n",
    "`9th June 2021`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting the Falcon9 Launch Wiki page from its URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will request the Falcon9 Launch HTML page as an HTTP response by using the HTTP GET method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use requests.get() method with the static_url\n",
    "response = requests.get(static_url)\n",
    "# We will assign the response to an object\n",
    "html = response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a `BeautifulSoup` object from the HTML `response`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify if the `BeautifulSoup` object was created properly, we will print the page title using the soup.title attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>List of Falcon 9 and Falcon Heavy launches - Wikipedia</title>]\n"
     ]
    }
   ],
   "source": [
    "soup.find_all('title', limit=1)\n",
    "print (soup.find_all(\"title\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all column/variable names from the HTML table header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to collect all relevant column names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the find_all function in the BeautifulSoup object, with element type `table`\n",
    "html_tables = []\n",
    "html_tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target is the third table which contains the actual launch records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_launch_table = html_tables[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will iterate through the `<th>` elements and apply the `extract_column_from_header()` to extract the column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "# Using the find_all() function with `th` element on first_launch_table\n",
    "first_launch_table.find_all('th')\n",
    "# Iterate through each th element and apply the extract_column_from_header() to get column name\n",
    "for row in first_launch_table.find_all('th'):\n",
    "    cols=row.find_all('td')\n",
    "    name=extract_column_from_header(row)\n",
    "# Append the Non-empty column names into a list called column_names\n",
    "    if name is not None and len(name) > 0:\n",
    "         column_names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the column_names list to see the extracted column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flight No.', 'Date and time ( )', 'Launch site', 'Payload', 'Payload mass', 'Orbit', 'Customer', 'Launch outcome']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a data frame by parsing the launch HTML tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an empty dictionary with keys from the extracted column names in `column_names`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_dict= dict.fromkeys(column_names)\n",
    "\n",
    "# Remove an irrelvant column\n",
    "del launch_dict['Date and time ( )']\n",
    "\n",
    "# Let's initial the launch_dict with each value to be an empty list\n",
    "launch_dict['Flight No.'] = []\n",
    "launch_dict['Launch site'] = []\n",
    "launch_dict['Payload'] = []\n",
    "launch_dict['Payload mass'] = []\n",
    "launch_dict['Orbit'] = []\n",
    "launch_dict['Customer'] = []\n",
    "launch_dict['Launch outcome'] = []\n",
    "# Added some new columns\n",
    "launch_dict['Version Booster']=[]\n",
    "launch_dict['Booster landing']=[]\n",
    "launch_dict['Date']=[]\n",
    "launch_dict['Time']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must fill up the `launch_dict` with launch records extracted from table rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_row = 0\n",
    "#Extract each table \n",
    "for table_number,table in enumerate(soup.find_all('table',\"wikitable plainrowheaders collapsible\")):\n",
    "   # get table row \n",
    "    for rows in table.find_all(\"tr\"):\n",
    "        #check to see if first table heading is as number corresponding to launch a number \n",
    "        if rows.th:\n",
    "            if rows.th.string:\n",
    "                flight_number=rows.th.string.strip()\n",
    "                flag=flight_number.isdigit()\n",
    "        else:\n",
    "            flag=False\n",
    "        #get table element \n",
    "        row=rows.find_all('td')\n",
    "        #if it is number save cells in a dictonary \n",
    "        if flag:\n",
    "            extracted_row += 1\n",
    "            # Flight Number value\n",
    "            launch_dict[\"Flight No.\"].append(flight_number)\n",
    "            datatimelist=date_time(row[0])\n",
    "            \n",
    "            # Date value\n",
    "            date = datatimelist[0].strip(',')\n",
    "            launch_dict[\"Date\"].append(date)\n",
    "            \n",
    "            # Time value\n",
    "            time = datatimelist[1]\n",
    "            launch_dict[\"Time\"].append(time)\n",
    "              \n",
    "            # Booster version\n",
    "            bv=booster_version(row[1])\n",
    "            if not(bv):\n",
    "                bv=row[1].a.string\n",
    "            launch_dict[\"Version Booster\"].append(bv)\n",
    "            \n",
    "            # Launch Site\n",
    "            launch_site = row[2].a.string\n",
    "            launch_dict[\"Launch site\"].append(launch_site)\n",
    "            \n",
    "            # Payload\n",
    "            payload = row[3].a.string\n",
    "            launch_dict[\"Payload\"].append(payload)\n",
    "            \n",
    "            # Payload Mass\n",
    "            payload_mass = get_mass(row[4])\n",
    "            launch_dict[\"Payload mass\"].append(payload_mass)\n",
    "            \n",
    "            # Orbit\n",
    "            orbit = row[5].a.string\n",
    "            launch_dict[\"Orbit\"].append(orbit)\n",
    "            \n",
    "            # Customer\n",
    "            if (row[6].a is not None):\n",
    "                customer=row[6].a.string\n",
    "            else:\n",
    "                customer=row[6].string\n",
    "            launch_dict['Customer'].append(customer)\n",
    "            \n",
    "            # Launch outcome\n",
    "            launch_outcome = list(row[7].strings)[0]\n",
    "            launch_dict[\"Launch outcome\"].append(launch_outcome)\n",
    "            \n",
    "            # Booster landing\n",
    "            booster_landing = landing_status(row[8])\n",
    "            launch_dict[\"Booster landing\"].append(booster_landing)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a Pandas dataframe from `launch_dict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(launch_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export it to a <b>CSV</b> for our next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('spacex_web_scraped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mitchell Fargher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit: <a href=\"https://www.linkedin.com/in/nayefaboutayoun/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\">Nayef Abou Tayoun</a>, <a href=\"https://www.linkedin.com/in/yan-luo-96288783/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2021-01-01\">Yan Luo</a>, and the IBM Data Science Professional Certifiate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
